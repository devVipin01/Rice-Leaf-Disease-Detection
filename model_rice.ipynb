{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4423,"status":"ok","timestamp":1678536588492,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"NV4yq64niG4i"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Model\n","from keras.layers import Dense\n","\n","from keras import models, layers\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7206,"status":"ok","timestamp":1678536598119,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"IiSbTujaicE-","outputId":"ab13f351-07ef-4a1b-e0fd-9e07225a841c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 440 files belonging to 4 classes.\n"]}],"source":["IMAGE_SIZE = 256\n","BATCH_SIZE = 32\n","CHANNELS = 3\n","EPOCHS = 40\n","dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","        '/content/drive/MyDrive/Colab Notebooks/app2/Rice_Images_Data',\n","        shuffle=True,\n","        image_size = (IMAGE_SIZE, IMAGE_SIZE),\n","        batch_size = BATCH_SIZE\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvgzcCZNi5f1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":686,"status":"ok","timestamp":1678536603246,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"5OPdkjOwKj0U"},"outputs":[],"source":["class_names = dataset.class_names"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678536613730,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"Tz9KCO0qi6rA"},"outputs":[],"source":["def get_dataset_partition_tf (ds, train_split=0.7, val_split=0.2, test_split=0.1, shuffle=True, shuffle_size=10000):\n","    \n","    ds_size = len(ds) #dataset size\n","    if shuffle:\n","        ds = ds.shuffle(shuffle_size, seed=12)\n","        \n","    train_size = int(train_split * ds_size) #train size converted to intger to avoid float\n","    val_size = int(val_split * ds_size)\n","    \n","    train_ds = ds.take(train_size)\n","    val_ds = ds.skip(train_size).take(val_size)\n","    test_ds = ds.skip(train_size).skip(val_size)\n","    \n","    return train_ds, val_ds, test_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1qWMwGUjBW-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":672,"status":"ok","timestamp":1678536617985,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"C7zbK_fOKz0W"},"outputs":[],"source":["train_ds, val_ds, test_ds = get_dataset_partition_tf(dataset)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1678536620364,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"I7BQZ5YZjG1R"},"outputs":[],"source":["train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE) #buffer_size=tf.data.AUTOTUNE is to allow tf determine the batch size\n","val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n","test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":899,"status":"ok","timestamp":1678536624039,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"4IsgipQrjJTQ"},"outputs":[],"source":["data_augmentation = tf.keras.Sequential([\n","    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n","    layers.experimental.preprocessing.RandomRotation(0.3),\n","])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":847,"status":"ok","timestamp":1678536629755,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"GVA-QU-ljN3e"},"outputs":[],"source":["resize_and_rescale = tf.keras.Sequential([\n","    layers.experimental.preprocessing.Resizing(IMAGE_SIZE,IMAGE_SIZE), #resize new inputs \n","    layers.experimental.preprocessing.Rescaling(1.0/255) #scale down RGB\n","])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":970,"status":"ok","timestamp":1678536634603,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"K3Ng8pTyjTgZ","outputId":"6acc2de8-a063-4ba6-8c57-66eaa516fda8"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]}],"source":["input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n","n_classes = 4\n","model = models.Sequential([\n","    resize_and_rescale,\n","    data_augmentation,\n","    layers.Conv2D(32, (3,3), activation='relu', input_shape = input_shape), #google Conv2D for all arguement. 32=no. of layers\n","    layers.MaxPooling2D((2,2)),\n","    layers.Dropout(0.1),\n","    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n","    layers.MaxPooling2D((2,2)),\n","    layers.Dropout(0.1),\n","    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n","    layers.MaxPooling2D((2,2)),\n","    layers.Dropout(0.1),\n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'), #dense layer of 64 neurons\n","    layers.Dense(n_classes, activation='softmax'), #softmax normalizes the prob of classes.  \n","])\n","model.build(input_shape=input_shape) "]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1678536639426,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"7deFB3jYjYfL"},"outputs":[],"source":["model.compile(\n","    optimizer='Adagrad',\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","    metrics=['accuracy'] #track training process\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1678536643927,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"0e-Y7KWcjcRu","outputId":"9a8f840a-aca1-43be-8550-4836eb0a619b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_1 (Sequential)   (32, 256, 256, 3)         0         \n","                                                                 \n"," sequential (Sequential)     (None, 256, 256, 3)       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 254, 254, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 127, 127, 32)      0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 62, 62, 64)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 30, 30, 64)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 57600)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                3686464   \n","                                                                 \n"," dense_1 (Dense)             (None, 4)                 260       \n","                                                                 \n","=================================================================\n","Total params: 3,743,044\n","Trainable params: 3,743,044\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200626,"status":"ok","timestamp":1678536857016,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"Ab1Vn1OGjhbt","outputId":"a9682e1f-84da-4719-85c9-07a294ec2f90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"name":"stdout","output_type":"stream","text":["9/9 [==============================] - 126s 344ms/step - loss: 1.4242 - accuracy: 0.2536 - val_loss: 1.3971 - val_accuracy: 0.2500\n","Epoch 2/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.4027 - accuracy: 0.2786 - val_loss: 1.3940 - val_accuracy: 0.2500\n","Epoch 3/40\n","9/9 [==============================] - 2s 173ms/step - loss: 1.3894 - accuracy: 0.2821 - val_loss: 1.3926 - val_accuracy: 0.2188\n","Epoch 4/40\n","9/9 [==============================] - 2s 214ms/step - loss: 1.3909 - accuracy: 0.2571 - val_loss: 1.3873 - val_accuracy: 0.2500\n","Epoch 5/40\n","9/9 [==============================] - 1s 163ms/step - loss: 1.3905 - accuracy: 0.2714 - val_loss: 1.3863 - val_accuracy: 0.2500\n","Epoch 6/40\n","9/9 [==============================] - 1s 160ms/step - loss: 1.3876 - accuracy: 0.2714 - val_loss: 1.3885 - val_accuracy: 0.2500\n","Epoch 7/40\n","9/9 [==============================] - 1s 161ms/step - loss: 1.3890 - accuracy: 0.2429 - val_loss: 1.3901 - val_accuracy: 0.2500\n","Epoch 8/40\n","9/9 [==============================] - 1s 158ms/step - loss: 1.3865 - accuracy: 0.2571 - val_loss: 1.3901 - val_accuracy: 0.2500\n","Epoch 9/40\n","9/9 [==============================] - 1s 160ms/step - loss: 1.3885 - accuracy: 0.2429 - val_loss: 1.3872 - val_accuracy: 0.2500\n","Epoch 10/40\n","9/9 [==============================] - 2s 200ms/step - loss: 1.3874 - accuracy: 0.2750 - val_loss: 1.3888 - val_accuracy: 0.2500\n","Epoch 11/40\n","9/9 [==============================] - 2s 216ms/step - loss: 1.3831 - accuracy: 0.2750 - val_loss: 1.3873 - val_accuracy: 0.2500\n","Epoch 12/40\n","9/9 [==============================] - 1s 160ms/step - loss: 1.3871 - accuracy: 0.2821 - val_loss: 1.3885 - val_accuracy: 0.2500\n","Epoch 13/40\n","9/9 [==============================] - 1s 161ms/step - loss: 1.3855 - accuracy: 0.2429 - val_loss: 1.3915 - val_accuracy: 0.2656\n","Epoch 14/40\n","9/9 [==============================] - 1s 160ms/step - loss: 1.3863 - accuracy: 0.2714 - val_loss: 1.3908 - val_accuracy: 0.2500\n","Epoch 15/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3865 - accuracy: 0.2607 - val_loss: 1.3907 - val_accuracy: 0.2500\n","Epoch 16/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3856 - accuracy: 0.2893 - val_loss: 1.3899 - val_accuracy: 0.2500\n","Epoch 17/40\n","9/9 [==============================] - 1s 167ms/step - loss: 1.3817 - accuracy: 0.2964 - val_loss: 1.3907 - val_accuracy: 0.2500\n","Epoch 18/40\n","9/9 [==============================] - 2s 220ms/step - loss: 1.3846 - accuracy: 0.2571 - val_loss: 1.3892 - val_accuracy: 0.2500\n","Epoch 19/40\n","9/9 [==============================] - 1s 161ms/step - loss: 1.3825 - accuracy: 0.2964 - val_loss: 1.3879 - val_accuracy: 0.2500\n","Epoch 20/40\n","9/9 [==============================] - 2s 198ms/step - loss: 1.3805 - accuracy: 0.2750 - val_loss: 1.3899 - val_accuracy: 0.2500\n","Epoch 21/40\n","9/9 [==============================] - 2s 210ms/step - loss: 1.3884 - accuracy: 0.2750 - val_loss: 1.3889 - val_accuracy: 0.2500\n","Epoch 22/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3821 - accuracy: 0.3036 - val_loss: 1.3901 - val_accuracy: 0.2500\n","Epoch 23/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3835 - accuracy: 0.2893 - val_loss: 1.3885 - val_accuracy: 0.2500\n","Epoch 24/40\n","9/9 [==============================] - 2s 211ms/step - loss: 1.3853 - accuracy: 0.2714 - val_loss: 1.3873 - val_accuracy: 0.2500\n","Epoch 25/40\n","9/9 [==============================] - 2s 210ms/step - loss: 1.3821 - accuracy: 0.2929 - val_loss: 1.3871 - val_accuracy: 0.2500\n","Epoch 26/40\n","9/9 [==============================] - 1s 160ms/step - loss: 1.3823 - accuracy: 0.2964 - val_loss: 1.3882 - val_accuracy: 0.2500\n","Epoch 27/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3770 - accuracy: 0.3107 - val_loss: 1.3867 - val_accuracy: 0.2500\n","Epoch 28/40\n","9/9 [==============================] - 1s 161ms/step - loss: 1.3805 - accuracy: 0.2786 - val_loss: 1.3876 - val_accuracy: 0.2500\n","Epoch 29/40\n","9/9 [==============================] - 1s 160ms/step - loss: 1.3819 - accuracy: 0.2750 - val_loss: 1.3880 - val_accuracy: 0.2500\n","Epoch 30/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3817 - accuracy: 0.2821 - val_loss: 1.3864 - val_accuracy: 0.2500\n","Epoch 31/40\n","9/9 [==============================] - 2s 197ms/step - loss: 1.3755 - accuracy: 0.2714 - val_loss: 1.3886 - val_accuracy: 0.2500\n","Epoch 32/40\n","9/9 [==============================] - 2s 210ms/step - loss: 1.3775 - accuracy: 0.2929 - val_loss: 1.3892 - val_accuracy: 0.2500\n","Epoch 33/40\n","9/9 [==============================] - 1s 160ms/step - loss: 1.3807 - accuracy: 0.2857 - val_loss: 1.3873 - val_accuracy: 0.2500\n","Epoch 34/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3759 - accuracy: 0.2786 - val_loss: 1.3859 - val_accuracy: 0.2500\n","Epoch 35/40\n","9/9 [==============================] - 1s 162ms/step - loss: 1.3809 - accuracy: 0.2929 - val_loss: 1.3854 - val_accuracy: 0.2500\n","Epoch 36/40\n","9/9 [==============================] - 1s 164ms/step - loss: 1.3763 - accuracy: 0.2964 - val_loss: 1.3865 - val_accuracy: 0.2500\n","Epoch 37/40\n","9/9 [==============================] - 1s 163ms/step - loss: 1.3762 - accuracy: 0.2679 - val_loss: 1.3871 - val_accuracy: 0.2500\n","Epoch 38/40\n","9/9 [==============================] - 2s 168ms/step - loss: 1.3754 - accuracy: 0.3000 - val_loss: 1.3910 - val_accuracy: 0.2500\n","Epoch 39/40\n","9/9 [==============================] - 2s 187ms/step - loss: 1.3730 - accuracy: 0.3143 - val_loss: 1.3903 - val_accuracy: 0.2500\n","Epoch 40/40\n","9/9 [==============================] - 2s 192ms/step - loss: 1.3744 - accuracy: 0.3071 - val_loss: 1.3849 - val_accuracy: 0.2500\n"]}],"source":["history = model.fit(\n","    train_ds,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    verbose=1,\n","    validation_data=val_ds\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":664,"status":"ok","timestamp":1678537326071,"user":{"displayName":"Naveen Dwivedi","userId":"11383769637630104270"},"user_tz":-330},"id":"FBoUNyg6mEjO"},"outputs":[],"source":["model.save('/content/drive/MyDrive/Colab Notebooks/app2/model.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOcj3XhJi6R4DLk8HSMhQip","mount_file_id":"1HuIiEpOGIhy9laorh3uFqnYvJFO-3zze","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
